{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 397693,
          "sourceType": "datasetVersion",
          "datasetId": 176381
        },
        {
          "sourceId": 12821487,
          "sourceType": "datasetVersion",
          "datasetId": 8107918
        }
      ],
      "dockerImageVersionId": 30260,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Bullying detection project",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "xrtbfpVHLx-C"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "mohamedmustafa_real_life_violence_situations_dataset_path = kagglehub.dataset_download('mohamedmustafa/real-life-violence-situations-dataset')\n",
        "selinazarzour_mobilenetv2_path = kagglehub.dataset_download('selinazarzour/mobilenetv2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "n46cC6HYLx-D"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing the required libraries**"
      ],
      "metadata": {
        "id": "ZsKYkocGm0La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow\n",
        "import keras\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn\")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "KN35l9ZJ3aTh",
        "execution": {
          "iopub.status.busy": "2025-08-21T00:23:13.465644Z",
          "iopub.execute_input": "2025-08-21T00:23:13.465994Z",
          "iopub.status.idle": "2025-08-21T00:23:20.519994Z",
          "shell.execute_reply.started": "2025-08-21T00:23:13.465911Z",
          "shell.execute_reply": "2025-08-21T00:23:20.518876Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize the Data (Bullying Detection)**\n",
        "This notebook is now tailored for detecting bullying in videos, using a small, personalized dataset."
      ],
      "metadata": {
        "id": "2JxJyU0e3aTn",
        "_kg_hide-input": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# To Show a Video in Notebook\n",
        "def Play_Video(filepath):\n",
        "    html = ''\n",
        "    video = open(filepath,'rb').read()\n",
        "    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
        "    html += '<video width=640 muted controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src\n",
        "    return HTML(html)"
      ],
      "metadata": {
        "id": "Sn7l5xJlmtrf",
        "execution": {
          "iopub.status.busy": "2025-08-20T23:13:48.073622Z",
          "iopub.execute_input": "2025-08-20T23:13:48.074096Z",
          "iopub.status.idle": "2025-08-20T23:13:48.080583Z",
          "shell.execute_reply.started": "2025-08-20T23:13:48.07406Z",
          "shell.execute_reply": "2025-08-20T23:13:48.079286Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes Directories\n",
        "NonBullyingVideos_Dir = \"../input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence/\"\n",
        "BullyingVideos_Dir = \"../input/real-life-violence-situations-dataset/Real Life Violence Dataset/Violence/\"\n",
        "\n",
        "# Retrieve the list of all the video files present in the Class Directory.\n",
        "NonBullying_files_names_list = os.listdir(NonBullyingVideos_Dir)\n",
        "Bullying_files_names_list = os.listdir(BullyingVideos_Dir)\n",
        "\n",
        "# Randomly select 20 videos from each class for a small, personal dataset.\n",
        "NonBullying_sampled = random.sample(NonBullying_files_names_list, 20)\n",
        "Bullying_sampled = random.sample(Bullying_files_names_list, 20)\n",
        "\n",
        "# Randomly select a video file from the Classes Directory for visualization.\n",
        "Random_NonBullying_Video = random.choice(NonBullying_sampled)\n",
        "Random_Bullying_Video = random.choice(Bullying_sampled)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "WzJy3lsU3aTp",
        "execution": {
          "iopub.status.busy": "2025-08-20T23:13:51.089128Z",
          "iopub.execute_input": "2025-08-20T23:13:51.089506Z",
          "iopub.status.idle": "2025-08-20T23:13:51.175811Z",
          "shell.execute_reply.started": "2025-08-20T23:13:51.089473Z",
          "shell.execute_reply": "2025-08-20T23:13:51.174561Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Play Random NonBullying Video**"
      ],
      "metadata": {
        "id": "pq5KrFGd-HJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Play_Video(f\"{NonBullyingVideos_Dir}/{Random_NonBullying_Video}\")"
      ],
      "metadata": {
        "id": "P2wg6bCP9C3S",
        "execution": {
          "iopub.status.busy": "2025-08-20T23:14:05.177093Z",
          "iopub.execute_input": "2025-08-20T23:14:05.177458Z",
          "iopub.status.idle": "2025-08-20T23:14:05.211596Z",
          "shell.execute_reply.started": "2025-08-20T23:14:05.17743Z",
          "shell.execute_reply": "2025-08-20T23:14:05.210248Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Play Random Bullying Video**"
      ],
      "metadata": {
        "id": "eDllFj2y-LXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Play_Video(f\"{BullyingVideos_Dir}/{Random_Bullying_Video}\")"
      ],
      "metadata": {
        "id": "AdbW5DIYnk2D",
        "execution": {
          "iopub.status.busy": "2025-08-20T23:14:19.349295Z",
          "iopub.execute_input": "2025-08-20T23:14:19.350135Z",
          "iopub.status.idle": "2025-08-20T23:14:19.403336Z",
          "shell.execute_reply.started": "2025-08-20T23:14:19.350098Z",
          "shell.execute_reply": "2025-08-20T23:14:19.402091Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracting Frames**"
      ],
      "metadata": {
        "id": "ySOhHqy83aTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the height and width to which each video frame will be resized in our dataset.\n",
        "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
        "\n",
        "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
        "SEQUENCE_LENGTH = 16\n",
        "\n",
        "DATASET_DIR = \"../input/real-life-violence-situations-dataset/Real Life Violence Dataset/\"\n",
        "\n",
        "# Use new class names\n",
        "CLASSES_LIST = [\"NonBullying\",\"Bullying\"]\n",
        "\n",
        "# Note: Only 20 videos per class will be used for this personalized dataset."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:14:42.220169Z",
          "iopub.execute_input": "2025-08-20T23:14:42.221154Z",
          "iopub.status.idle": "2025-08-20T23:14:42.226275Z",
          "shell.execute_reply.started": "2025-08-20T23:14:42.221117Z",
          "shell.execute_reply": "2025-08-20T23:14:42.2251Z"
        },
        "id": "1arHoOHI3aTr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_extraction(video_path):\n",
        "\n",
        "    frames_list = []\n",
        "\n",
        "    # Read the Video File\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the total number of frames in the video.\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the the interval after which frames will be added to the list.\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
        "\n",
        "    # Iterate through the Video Frames.\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        # Set the current frame position of the video.\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        # Reading the frame from the video.\n",
        "        success, frame = video_reader.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed height and width.\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "\n",
        "        # Normalize the resized frame\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        # Append the normalized frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "\n",
        "    video_reader.release()\n",
        "\n",
        "    return frames_list"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:15:03.090348Z",
          "iopub.execute_input": "2025-08-20T23:15:03.091099Z",
          "iopub.status.idle": "2025-08-20T23:15:03.098668Z",
          "shell.execute_reply.started": "2025-08-20T23:15:03.091055Z",
          "shell.execute_reply": "2025-08-20T23:15:03.097497Z"
        },
        "id": "-yB8ePeC3aTs",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the Data**"
      ],
      "metadata": {
        "id": "uqAqiZxD3aTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset():\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Use the sampled video lists for each class\n",
        "    class_samples = {\n",
        "        'NonBullying': NonBullying_sampled,\n",
        "        'Bullying': Bullying_sampled\n",
        "    }\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        print(f'Extracting Data of Class: {class_name}')\n",
        "        # Get the list of video files present in the sampled list for this class\n",
        "        files_list = class_samples[class_name]\n",
        "        for file_name in files_list:\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name if class_name == 'NonBullying' else 'Bullying', file_name)\n",
        "            # For folder mapping: NonBullying -> NonViolence, Bullying -> Violence\n",
        "            if class_name == 'NonBullying':\n",
        "                video_file_path = os.path.join(DATASET_DIR, 'NonViolence', file_name)\n",
        "            else:\n",
        "                video_file_path = os.path.join(DATASET_DIR, 'Violence', file_name)\n",
        "            frames = frames_extraction(video_file_path)\n",
        "            if len(frames) == SEQUENCE_LENGTH:\n",
        "                features.append(frames)\n",
        "                labels.append(class_index)\n",
        "                video_files_paths.append(video_file_path)\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)\n",
        "    return features, labels, video_files_paths"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:17:31.594977Z",
          "iopub.execute_input": "2025-08-20T23:17:31.595396Z",
          "iopub.status.idle": "2025-08-20T23:17:31.605116Z",
          "shell.execute_reply.started": "2025-08-20T23:17:31.595362Z",
          "shell.execute_reply": "2025-08-20T23:17:31.60385Z"
        },
        "id": "vj_AQqju3aTu",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset.\n",
        "features, labels, video_files_paths = create_dataset()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:17:44.681589Z",
          "iopub.execute_input": "2025-08-20T23:17:44.682805Z",
          "iopub.status.idle": "2025-08-20T23:18:04.852961Z",
          "shell.execute_reply.started": "2025-08-20T23:17:44.682729Z",
          "shell.execute_reply": "2025-08-20T23:18:04.851686Z"
        },
        "id": "rgpokUY83aTv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the extracted data\n",
        "np.save(\"features.npy\",features)\n",
        "np.save(\"labels.npy\",labels)\n",
        "np.save(\"video_files_paths.npy\",video_files_paths)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:18:29.32973Z",
          "iopub.execute_input": "2025-08-20T23:18:29.330107Z",
          "iopub.status.idle": "2025-08-20T23:18:29.395188Z",
          "shell.execute_reply.started": "2025-08-20T23:18:29.330078Z",
          "shell.execute_reply": "2025-08-20T23:18:29.394038Z"
        },
        "id": "Hu8NKv4H3aTv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels, video_files_paths = np.load(\"features.npy\") , np.load(\"labels.npy\") ,  np.load(\"video_files_paths.npy\")"
      ],
      "metadata": {
        "id": "9KOPtXlH3aTw",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T23:18:33.658757Z",
          "iopub.execute_input": "2025-08-20T23:18:33.659786Z",
          "iopub.status.idle": "2025-08-20T23:18:33.699407Z",
          "shell.execute_reply.started": "2025-08-20T23:18:33.659731Z",
          "shell.execute_reply": "2025-08-20T23:18:33.698452Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoding and Splitting Training-Testing Sets (Bullying/NonBullying)**"
      ],
      "metadata": {
        "id": "lkN8bgxH3aTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert labels into one-hot-encoded vectors\n",
        "one_hot_encoded_labels = to_categorical(labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:19:35.807796Z",
          "iopub.execute_input": "2025-08-20T23:19:35.808193Z",
          "iopub.status.idle": "2025-08-20T23:19:35.813321Z",
          "shell.execute_reply.started": "2025-08-20T23:19:35.808162Z",
          "shell.execute_reply": "2025-08-20T23:19:35.812195Z"
        },
        "id": "SIN6V5GN3aTw",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the Data into Train (80%) and Test Set (20%) for small dataset.\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    features, one_hot_encoded_labels, test_size=0.1, shuffle=True, random_state=42\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:19:38.273877Z",
          "iopub.execute_input": "2025-08-20T23:19:38.274248Z",
          "iopub.status.idle": "2025-08-20T23:19:38.307163Z",
          "shell.execute_reply.started": "2025-08-20T23:19:38.274219Z",
          "shell.execute_reply": "2025-08-20T23:19:38.306139Z"
        },
        "id": "P0uFnKvq3aTx",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_train.shape,labels_train.shape )\n",
        "print(features_test.shape, labels_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:19:44.358126Z",
          "iopub.execute_input": "2025-08-20T23:19:44.358506Z",
          "iopub.status.idle": "2025-08-20T23:19:44.365045Z",
          "shell.execute_reply.started": "2025-08-20T23:19:44.358477Z",
          "shell.execute_reply": "2025-08-20T23:19:44.363632Z"
        },
        "id": "8X0LeeVW3aTx",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing MobileNet and Fine-Tuning it for Bullying Detection**"
      ],
      "metadata": {
        "id": "bLGa3mfdtu_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If running on Kaggle, first copy the weights file from your Dataset to the Keras models cache\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "src = '/kaggle/input/mobilenetv2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n",
        "dst_dir = os.path.expanduser('~/.keras/models')\n",
        "os.makedirs(dst_dir, exist_ok=True)\n",
        "dst = os.path.join(dst_dir, 'mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5')\n",
        "if not os.path.exists(dst):\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "mobilenet = MobileNetV2( include_top=False , weights=\"imagenet\")\n",
        "\n",
        "#Fine-Tuning to make the last 40 layer trainable\n",
        "mobilenet.trainable=True\n",
        "\n",
        "for layer in mobilenet.layers[:-40]:\n",
        "  layer.trainable=False\n",
        "\n",
        "#mobilenet.summary()"
      ],
      "metadata": {
        "id": "Tpo2Q-Uf3aT8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T23:30:53.300736Z",
          "iopub.execute_input": "2025-08-20T23:30:53.304006Z",
          "iopub.status.idle": "2025-08-20T23:30:54.609423Z",
          "shell.execute_reply.started": "2025-08-20T23:30:53.303848Z",
          "shell.execute_reply": "2025-08-20T23:30:54.607872Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building The Model for Bullying/NonBullying**"
      ],
      "metadata": {
        "id": "PFfDOTnZ3aTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    ########################################################################################################################\n",
        "\n",
        "    #Specifying Input to match features shape\n",
        "    model.add(Input(shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
        "\n",
        "    # Passing mobilenet in the TimeDistributed layer to handle the sequence\n",
        "    model.add(TimeDistributed(mobilenet))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "\n",
        "    lstm_fw = LSTM(units=32)\n",
        "    lstm_bw = LSTM(units=32, go_backwards = True)\n",
        "\n",
        "    model.add(Bidirectional(lstm_fw, backward_layer = lstm_bw))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(256,activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(64,activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n",
        "\n",
        "    ########################################################################################################################\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:31:25.037518Z",
          "iopub.execute_input": "2025-08-20T23:31:25.037946Z",
          "iopub.status.idle": "2025-08-20T23:31:25.048273Z",
          "shell.execute_reply.started": "2025-08-20T23:31:25.037913Z",
          "shell.execute_reply": "2025-08-20T23:31:25.047089Z"
        },
        "id": "CWtYR7bM3aT9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Constructing the Model\n",
        "MoBiLSTM_model = create_model()\n",
        "\n",
        "# Plot the structure of the contructed LRCN model.\n",
        "plot_model(MoBiLSTM_model, to_file = 'MobBiLSTM_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
      ],
      "metadata": {
        "id": "auo9g9rpmBOS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T23:31:32.399896Z",
          "iopub.execute_input": "2025-08-20T23:31:32.400276Z",
          "iopub.status.idle": "2025-08-20T23:31:35.670202Z",
          "shell.execute_reply.started": "2025-08-20T23:31:32.400247Z",
          "shell.execute_reply": "2025-08-20T23:31:35.668548Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Specifying Callbacks and Fitting**"
      ],
      "metadata": {
        "id": "c_jvIgP9wEh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Early Stopping Callback to monitor the accuracy\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 10, restore_best_weights = True)\n",
        "\n",
        "# Create ReduceLROnPlateau Callback to reduce overfitting by decreasing learning\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                  factor=0.6,\n",
        "                                                  patience=5,\n",
        "                                                  min_lr=0.00005,\n",
        "                                                  verbose=1)\n",
        "\n",
        "# Compiling the model\n",
        "MoBiLSTM_model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = [\"accuracy\"])\n",
        "\n",
        "# Fitting the model\n",
        "MobBiLSTM_model_history = MoBiLSTM_model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 8 ,\n",
        "                                             shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback,reduce_lr])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:31:48.245975Z",
          "iopub.execute_input": "2025-08-20T23:31:48.246395Z",
          "iopub.status.idle": "2025-08-20T23:32:30.339496Z",
          "shell.execute_reply.started": "2025-08-20T23:31:48.246358Z",
          "shell.execute_reply": "2025-08-20T23:32:30.338178Z"
        },
        "id": "oA-QWlSV3aT_",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation_history = MoBiLSTM_model.evaluate(features_test, labels_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:33:07.622978Z",
          "iopub.execute_input": "2025-08-20T23:33:07.623395Z",
          "iopub.status.idle": "2025-08-20T23:33:10.204126Z",
          "shell.execute_reply.started": "2025-08-20T23:33:07.623358Z",
          "shell.execute_reply": "2025-08-20T23:33:10.203225Z"
        },
        "id": "6577H1to3aT_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation (Bullying/NonBullying)**"
      ],
      "metadata": {
        "id": "lPGXI4C53aUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "\n",
        "    # Get the Epochs Count\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'orange', label = metric_name_2)\n",
        "\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    plt.legend()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:33:33.253461Z",
          "iopub.execute_input": "2025-08-20T23:33:33.253872Z",
          "iopub.status.idle": "2025-08-20T23:33:33.260827Z",
          "shell.execute_reply.started": "2025-08-20T23:33:33.253838Z",
          "shell.execute_reply": "2025-08-20T23:33:33.25957Z"
        },
        "id": "hyHkkNo93aUB",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(MobBiLSTM_model_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:33:37.341644Z",
          "iopub.execute_input": "2025-08-20T23:33:37.342063Z",
          "iopub.status.idle": "2025-08-20T23:33:37.577854Z",
          "shell.execute_reply.started": "2025-08-20T23:33:37.342031Z",
          "shell.execute_reply": "2025-08-20T23:33:37.576656Z"
        },
        "id": "-YIHQIr13aUB",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(MobBiLSTM_model_history, 'accuracy', 'val_accuracy', 'Total Loss vs Total Validation Loss')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:33:42.945069Z",
          "iopub.execute_input": "2025-08-20T23:33:42.94546Z",
          "iopub.status.idle": "2025-08-20T23:33:43.12961Z",
          "shell.execute_reply.started": "2025-08-20T23:33:42.945431Z",
          "shell.execute_reply": "2025-08-20T23:33:43.128557Z"
        },
        "id": "JUeYKvq23aUB",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicting the Test Set**"
      ],
      "metadata": {
        "id": "f8rpSPRGxzLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_predict = MoBiLSTM_model.predict(features_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:34:10.999181Z",
          "iopub.execute_input": "2025-08-20T23:34:10.999544Z",
          "iopub.status.idle": "2025-08-20T23:34:11.155302Z",
          "shell.execute_reply.started": "2025-08-20T23:34:10.999514Z",
          "shell.execute_reply": "2025-08-20T23:34:11.154058Z"
        },
        "id": "BCuJOPWn3aUC",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Decoding the data to use in Metrics\n",
        "# labels_predict = np.argmax(labels_predict , axis=1)\n",
        "# labels_test_normal = np.argmax(labels_test , axis=1)\n",
        "\n",
        "# Decoding the data to use in Metrics\n",
        "if len(labels_predict.shape) > 1:\n",
        "    labels_predict = np.argmax(labels_predict, axis=1)\n",
        "if len(labels_test.shape) > 1:\n",
        "    labels_test_normal = np.argmax(labels_test, axis=1)\n",
        "else:\n",
        "    labels_test_normal = labels_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:37:49.961611Z",
          "iopub.execute_input": "2025-08-20T23:37:49.962076Z",
          "iopub.status.idle": "2025-08-20T23:37:49.968498Z",
          "shell.execute_reply.started": "2025-08-20T23:37:49.962044Z",
          "shell.execute_reply": "2025-08-20T23:37:49.967214Z"
        },
        "id": "6PtV_By23aUC",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "labels_test_normal.shape , labels_predict.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:37:56.650265Z",
          "iopub.execute_input": "2025-08-20T23:37:56.650637Z",
          "iopub.status.idle": "2025-08-20T23:37:56.658225Z",
          "shell.execute_reply.started": "2025-08-20T23:37:56.650608Z",
          "shell.execute_reply": "2025-08-20T23:37:56.657028Z"
        },
        "id": "HP-sdFAj3aUC",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Score (Bullying/NonBullying)"
      ],
      "metadata": {
        "id": "JR45ydemygm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "AccScore = accuracy_score(labels_predict, labels_test_normal)\n",
        "print('Accuracy Score is : ', AccScore)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:38:18.400259Z",
          "iopub.execute_input": "2025-08-20T23:38:18.400661Z",
          "iopub.status.idle": "2025-08-20T23:38:18.408244Z",
          "shell.execute_reply.started": "2025-08-20T23:38:18.400627Z",
          "shell.execute_reply": "2025-08-20T23:38:18.406987Z"
        },
        "id": "99mVAuNu3aUC",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix (Bullying/NonBullying)"
      ],
      "metadata": {
        "id": "FMtS_I_MyiY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "ax= plt.subplot()\n",
        "cm=confusion_matrix(labels_test_normal, labels_predict)\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax);\n",
        "\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "ax.xaxis.set_ticklabels(['True', 'False']); ax.yaxis.set_ticklabels(['NonBullying', 'Bullying']);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:40:47.372871Z",
          "iopub.execute_input": "2025-08-20T23:40:47.373333Z",
          "iopub.status.idle": "2025-08-20T23:40:47.781524Z",
          "shell.execute_reply.started": "2025-08-20T23:40:47.373297Z",
          "shell.execute_reply": "2025-08-20T23:40:47.780288Z"
        },
        "id": "xzg5AVTC3aUD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification Report (Bullying/NonBullying)"
      ],
      "metadata": {
        "id": "zX8EOmSTypNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "ClassificationReport = classification_report(labels_test_normal,labels_predict)\n",
        "print('Classification Report is : \\n', ClassificationReport)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:41:31.58435Z",
          "iopub.execute_input": "2025-08-20T23:41:31.584792Z",
          "iopub.status.idle": "2025-08-20T23:41:31.598092Z",
          "shell.execute_reply.started": "2025-08-20T23:41:31.584755Z",
          "shell.execute_reply": "2025-08-20T23:41:31.596808Z"
        },
        "id": "pcWhopTm3aUD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction Frame By Frame (Bullying/NonBullying)**"
      ],
      "metadata": {
        "id": "p9kjBjoN3aUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_frames(video_file_path, output_file_path, SEQUENCE_LENGTH):\n",
        "\n",
        "    # Read from the video file.\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    # Get the width and height of the video.\n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # VideoWriter to store the output video in the disk.\n",
        "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('m', 'p', '4', 'v'),\n",
        "                                    video_reader.get(cv2.CAP_PROP_FPS), (original_video_width, original_video_height))\n",
        "\n",
        "    # Declare a queue to store video frames.\n",
        "    frames_queue = deque(maxlen = SEQUENCE_LENGTH)\n",
        "\n",
        "    # Store the predicted class in the video.\n",
        "    predicted_class_name = ''\n",
        "\n",
        "    # Iterate until the video is accessed successfully.\n",
        "    while video_reader.isOpened():\n",
        "\n",
        "        ok, frame = video_reader.read()\n",
        "\n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions.\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "\n",
        "        # Normalize the resized frame\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        # Appending the pre-processed frame into the frames list.\n",
        "        frames_queue.append(normalized_frame)\n",
        "\n",
        "        # We Need at Least number of SEQUENCE_LENGTH Frames to perform a prediction.\n",
        "        # Check if the number of frames in the queue are equal to the fixed sequence length.\n",
        "        if len(frames_queue) == SEQUENCE_LENGTH:\n",
        "\n",
        "            # Pass the normalized frames to the model and get the predicted probabilities.\n",
        "            predicted_labels_probabilities = MoBiLSTM_model.predict(np.expand_dims(frames_queue, axis = 0))[0]\n",
        "\n",
        "            # Get the index of class with highest probability.\n",
        "            predicted_label = np.argmax(predicted_labels_probabilities)\n",
        "\n",
        "            # Get the class name using the retrieved index.\n",
        "            predicted_class_name = CLASSES_LIST[predicted_label]\n",
        "\n",
        "        # Write predicted class name on top of the frame.\n",
        "        if predicted_class_name == \"Bullying\":\n",
        "            cv2.putText(frame, predicted_class_name, (5, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 12)\n",
        "        else:\n",
        "            cv2.putText(frame, predicted_class_name, (5, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 0), 12)\n",
        "\n",
        "        # Write The frame into the disk using the VideoWriter\n",
        "        video_writer.write(frame)\n",
        "\n",
        "    video_reader.release()\n",
        "    video_writer.release()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:42:41.553992Z",
          "iopub.execute_input": "2025-08-20T23:42:41.554428Z",
          "iopub.status.idle": "2025-08-20T23:42:41.56636Z",
          "shell.execute_reply.started": "2025-08-20T23:42:41.554392Z",
          "shell.execute_reply": "2025-08-20T23:42:41.565044Z"
        },
        "id": "90aMcgLB3aUD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_webcam(SEQUENCE_LENGTH=16):\n",
        "    # Open webcam\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    # Queue for frames\n",
        "    frames_queue = deque(maxlen=SEQUENCE_LENGTH)\n",
        "    predicted_class_name = \"\"\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize + normalize\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "        normalized_frame = resized_frame / 255.0\n",
        "\n",
        "        # Add to queue\n",
        "        frames_queue.append(normalized_frame)\n",
        "\n",
        "        # Predict when we have enough frames\n",
        "        if len(frames_queue) == SEQUENCE_LENGTH:\n",
        "            preds = MoBiLSTM_model.predict(\n",
        "                np.expand_dims(frames_queue, axis=0), verbose=0\n",
        "            )[0]\n",
        "            pred_label = np.argmax(preds)\n",
        "            predicted_class_name = CLASSES_LIST[pred_label]\n",
        "\n",
        "        # Draw label on frame\n",
        "        if predicted_class_name == \"Violence\":\n",
        "            color = (0, 0, 255)  # red\n",
        "        else:\n",
        "            color = (0, 255, 0)  # green\n",
        "\n",
        "        cv2.putText(frame, predicted_class_name, (20, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)\n",
        "\n",
        "        cv2.imshow(\"Real-time Violence Detection\", frame)\n",
        "\n",
        "        # Quit on \"q\"\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Run webcam\n",
        "predict_webcam()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ffv9GfN-Lx-I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"default\")\n",
        "\n",
        "# To show Random Frames from the saved output predicted video (output predicted video doesn't show on the notebook but can be downloaded)\n",
        "def show_pred_frames(pred_video_path):\n",
        "\n",
        "    plt.figure(figsize=(20,15))\n",
        "\n",
        "    video_reader = cv2.VideoCapture(pred_video_path)\n",
        "\n",
        "    # Get the number of frames in the video.\n",
        "    frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Get Random Frames from the video then Sort it\n",
        "    random_range = sorted(random.sample(range (SEQUENCE_LENGTH , frames_count ), 12))\n",
        "\n",
        "    for counter, random_index in enumerate(random_range, 1):\n",
        "\n",
        "        plt.subplot(5, 4, counter)\n",
        "\n",
        "        # Set the current frame position of the video.\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, random_index)\n",
        "\n",
        "        ok, frame = video_reader.read()\n",
        "\n",
        "        if not ok:\n",
        "          break\n",
        "\n",
        "        frame = cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.imshow(frame);ax.figure.set_size_inches(20,20);plt.tight_layout()\n",
        "\n",
        "    video_reader.release()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:42:45.55241Z",
          "iopub.execute_input": "2025-08-20T23:42:45.552847Z",
          "iopub.status.idle": "2025-08-20T23:42:45.563797Z",
          "shell.execute_reply.started": "2025-08-20T23:42:45.552807Z",
          "shell.execute_reply": "2025-08-20T23:42:45.562512Z"
        },
        "id": "RMzc9v5T3aUD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the output video path.\n",
        "test_videos_directory = 'test_videos'\n",
        "os.makedirs(test_videos_directory, exist_ok = True)\n",
        "\n",
        "output_video_file_path = f'{test_videos_directory}/Output-Test-Video.mp4'"
      ],
      "metadata": {
        "id": "TLoHFIZG1nfx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T23:42:52.051835Z",
          "iopub.execute_input": "2025-08-20T23:42:52.052268Z",
          "iopub.status.idle": "2025-08-20T23:42:52.058076Z",
          "shell.execute_reply.started": "2025-08-20T23:42:52.052193Z",
          "shell.execute_reply": "2025-08-20T23:42:52.056773Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying video to be predicted\n",
        "input_video_file_path = \"../input/real-life-violence-situations-dataset/Real Life Violence Dataset/Violence/V_378.mp4\"\n",
        "\n",
        "# Perform Prediction on the Test Video.\n",
        "predict_frames(input_video_file_path, output_video_file_path, SEQUENCE_LENGTH)\n",
        "\n",
        "# Show random frames from the output video\n",
        "show_pred_frames(output_video_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:43:17.768468Z",
          "iopub.execute_input": "2025-08-20T23:43:17.769435Z",
          "iopub.status.idle": "2025-08-20T23:43:32.350406Z",
          "shell.execute_reply.started": "2025-08-20T23:43:17.769395Z",
          "shell.execute_reply": "2025-08-20T23:43:32.349218Z"
        },
        "id": "zXBFNGU83aUE",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the actual video\n",
        "Play_Video(input_video_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:43:36.136913Z",
          "iopub.execute_input": "2025-08-20T23:43:36.137315Z",
          "iopub.status.idle": "2025-08-20T23:43:36.162939Z",
          "shell.execute_reply.started": "2025-08-20T23:43:36.137281Z",
          "shell.execute_reply": "2025-08-20T23:43:36.16176Z"
        },
        "id": "lYbKAUan3aUE",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying video to be predicted\n",
        "input_video_file_path = \"../input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence/NV_1.mp4\"\n",
        "\n",
        "# Perform Prediction on the Test Video.\n",
        "predict_frames(input_video_file_path, output_video_file_path, SEQUENCE_LENGTH)\n",
        "\n",
        "# Show random frames from the output video\n",
        "show_pred_frames(output_video_file_path)"
      ],
      "metadata": {
        "id": "aNOREFYZevVa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T23:43:41.148963Z",
          "iopub.execute_input": "2025-08-20T23:43:41.149397Z",
          "iopub.status.idle": "2025-08-20T23:43:55.310739Z",
          "shell.execute_reply.started": "2025-08-20T23:43:41.149359Z",
          "shell.execute_reply": "2025-08-20T23:43:55.30884Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the actual video\n",
        "Play_Video(input_video_file_path)"
      ],
      "metadata": {
        "id": "WqM0I5jueyKx",
        "execution": {
          "iopub.status.busy": "2025-08-20T23:43:59.476902Z",
          "iopub.execute_input": "2025-08-20T23:43:59.47727Z",
          "iopub.status.idle": "2025-08-20T23:43:59.693014Z",
          "shell.execute_reply.started": "2025-08-20T23:43:59.477244Z",
          "shell.execute_reply": "2025-08-20T23:43:59.691054Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction For The Video (Bullying/NonBullying)**"
      ],
      "metadata": {
        "id": "Q4-IYON63aUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_video(video_file_path, SEQUENCE_LENGTH):\n",
        "\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    # Get the width and height of the video.\n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Declare a list to store video frames we will extract.\n",
        "    frames_list = []\n",
        "\n",
        "    # Store the predicted class in the video.\n",
        "    predicted_class_name = ''\n",
        "\n",
        "    # Get the number of frames in the video.\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the interval after which frames will be added to the list.\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
        "\n",
        "    # Iterating the number of times equal to the fixed length of sequence.\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        # Set the current frame position of the video.\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        success, frame = video_reader.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions.\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "\n",
        "        # Normalize the resized frame.\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        # Appending the pre-processed frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    # Passing the  pre-processed frames to the model and get the predicted probabilities.\n",
        "    predicted_labels_probabilities = MoBiLSTM_model.predict(np.expand_dims(frames_list, axis = 0))[0]\n",
        "\n",
        "    # Get the index of class with highest probability.\n",
        "    predicted_label = np.argmax(predicted_labels_probabilities)\n",
        "\n",
        "    # Get the class name using the retrieved index.\n",
        "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
        "\n",
        "    # Display the predicted class along with the prediction confidence.\n",
        "    print(f'Predicted: {predicted_class_name}\\nConfidence: {predicted_labels_probabilities[predicted_label]}')\n",
        "\n",
        "    video_reader.release()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:44:11.549547Z",
          "iopub.execute_input": "2025-08-20T23:44:11.550336Z",
          "iopub.status.idle": "2025-08-20T23:44:11.560307Z",
          "shell.execute_reply.started": "2025-08-20T23:44:11.550295Z",
          "shell.execute_reply": "2025-08-20T23:44:11.559119Z"
        },
        "id": "p4gjtz-73aUE",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying video to be predicted\n",
        "input_video_file_path = \"../input/real-life-violence-situations-dataset/Real Life Violence Dataset/Violence/V_276.mp4\"\n",
        "\n",
        "# Perform Single Prediction on the Test Video.\n",
        "predict_video(input_video_file_path, SEQUENCE_LENGTH)\n",
        "\n",
        "# Play the actual video\n",
        "Play_Video(input_video_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-20T23:44:43.274162Z",
          "iopub.execute_input": "2025-08-20T23:44:43.275333Z",
          "iopub.status.idle": "2025-08-20T23:44:46.210994Z",
          "shell.execute_reply.started": "2025-08-20T23:44:43.27529Z",
          "shell.execute_reply": "2025-08-20T23:44:46.209516Z"
        },
        "id": "O6DQ5V-b3aUF",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying video to be predicted\n",
        "input_video_file_path = \"../input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence/NV_23.mp4\"\n",
        "\n",
        "# Perform Single Prediction on the Test Video.\n",
        "predict_video(input_video_file_path, SEQUENCE_LENGTH)\n",
        "\n",
        "# Play the actual video\n",
        "Play_Video(input_video_file_path)"
      ],
      "metadata": {
        "id": "nxwWGvUg3aUF",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T23:44:56.985651Z",
          "iopub.execute_input": "2025-08-20T23:44:56.986048Z",
          "iopub.status.idle": "2025-08-20T23:44:59.472311Z",
          "shell.execute_reply.started": "2025-08-20T23:44:56.986017Z",
          "shell.execute_reply": "2025-08-20T23:44:59.471161Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Github Repository :**"
      ],
      "metadata": {
        "id": "G4j6xxlpLx-J"
      }
    }
  ]
}